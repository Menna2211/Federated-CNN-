{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULr0-TOM6FPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57351417-a4e9-4191-8f16-c1f608a2e4ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUASjoeTgeRH"
      },
      "source": [
        "# Standard scientific Python imports and Import  classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0DE_9Grwhpd"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import linalg\n",
        "from numpy.linalg import norm\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from imutils import paths\n",
        "#We import sklearn.\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "\n",
        "import time\n",
        "import datetime as dt\n",
        "\n",
        "# We'll use matplotlib for graphics.\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Gik21ZgMDG"
      },
      "source": [
        "# Loading training and testing data (MINST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTdKcyI95lPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "b8b1864c-1a80-4050-cfeb-af13d978beba"
      },
      "source": [
        "# Load data.\n",
        "(X_train , y_train),(X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test  = X_test.astype('float32')\n",
        "X_train /= 255 # Original data is uint8 (0-255). Scale it to range [0,1].\n",
        "X_test  /= 255\n",
        "\n",
        "#binarize the labels\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.fit_transform(y_test)\n",
        "\n",
        "print(\"Training X matrix shape\", X_train.shape)\n",
        "print('---------------------------------------- ')\n",
        "print(\"Testing X matrix shape\", X_test.shape)\n",
        "print('---------------------------------------- ')\n",
        "print('y Train Shape is : ' , y_train.shape)\n",
        "print('---------------------------------------- ')\n",
        "print('y Test Shape is : ' , y_test.shape)\n",
        "print('---------------------------------------- ')\n",
        "print('All y is : ' , np.unique( y_train ))\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.style.use('ggplot')\n",
        "for i in  range(5)  :\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_train[i].reshape(28,28), cmap='gray', interpolation='nearest')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Training X matrix shape (60000, 28, 28, 1)\n",
            "---------------------------------------- \n",
            "Testing X matrix shape (10000, 28, 28, 1)\n",
            "---------------------------------------- \n",
            "y Train Shape is :  (60000, 10)\n",
            "---------------------------------------- \n",
            "y Test Shape is :  (10000, 10)\n",
            "---------------------------------------- \n",
            "All y is :  [0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_tN1nX9f0t-"
      },
      "source": [
        "# Creating clients and batching training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9JftlSfwmlj"
      },
      "source": [
        "def create_clients(image_list, label_list, num_clients, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as\n",
        "                data shards - tuple of images and label lists.\n",
        "        args:\n",
        "            image_list: a list of numpy arrays of training images\n",
        "            label_list:a list of binarized labels for each image\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1\n",
        "\n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    #randomize the data\n",
        "    data = list(zip(image_list, label_list))\n",
        "    random.shuffle(data)\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))}\n",
        "\n",
        "def batch_data(data_shard, batch_size):\n",
        "    '''Takes in a clients data shard and create a tfds object off it\n",
        "    args:\n",
        "        shard: a data, label constituting a client's data shard\n",
        "        bs:batch size\n",
        "    return:\n",
        "        tfds object'''\n",
        "    #seperate shard into data and labels lists\n",
        "    data, label = zip(*data_shard)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "    return dataset.shuffle(len(label)).batch(batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2SC8vXo7nwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "2a6e9c12-beac-48dd-a032-71f00b7f5918"
      },
      "source": [
        "#create clients\n",
        "comms_round = 10\n",
        "n_clients = 10\n",
        "batch_size = 128\n",
        "clients = create_clients(X_train, y_train, n_clients, initial='client')\n",
        "\n",
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data, batch_size)\n",
        "\n",
        "#process and batch the test set\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-30b67299160e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclients_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclients_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#process and batch the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3240d7a19845>\u001b[0m in \u001b[0;36mbatch_data\u001b[0;34m(data_shard, batch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#seperate shard into data and labels lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_shard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \"\"\"\n\u001b[0;32m--> 691\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3153\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3156\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    127\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 129\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCEJ-PmA8YRY"
      },
      "source": [
        "\n",
        "# Creating a CNN model with Keras\n",
        "\n",
        "* INPUT: 28 × 28 × 1\n",
        "* CONV5: 5 × 5 size, 32 filters, 1 stride\n",
        "* ReLU: max(0,hθ(x))\n",
        "* POOL: 2 × 2 size, 1 stride\n",
        "* CONV5: 5 × 5 size, 64 filters, 1 stride\n",
        "* ReLU: max(0,hθ(x))\n",
        "* POOL: 2 × 2 size, 1 stride\n",
        "* FC: 1024 Hidden Neurons\n",
        "* DROPOUT: p = 0.5\n",
        "* FC: 10 Output Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK1Bdwck2klE"
      },
      "source": [
        "lr = 0.02\n",
        "loss='squared_hinge'\n",
        "#'squared_hinge'    For SVM\n",
        "#'categorical_crossentropy'   For Softmax\n",
        "metrics = ['accuracy']\n",
        "optimizer = SGD(lr=lr,\n",
        "                decay=lr / comms_round,\n",
        "                momentum=0.9\n",
        "               )\n",
        "\n",
        "\n",
        "class SimpleMLP:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model = Sequential()\n",
        "        ############################\n",
        "        model.add(tf.keras.layers.Conv2D(32, (5,5), input_shape=shape, activation='relu'))\n",
        "        model.add(tf.keras.layers.MaxPool2D((2, 2)))\n",
        "        model.add(tf.keras.layers.Conv2D(64, (5,5), activation='relu'))\n",
        "        model.add(tf.keras.layers.MaxPool2D((2, 2)))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(Dense(1028, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        #############################\n",
        "        model.add(Dense(classes, kernel_regularizer='l2'))\n",
        "        model.add(Activation(\"linear\"))\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywVegJ1ClNkK"
      },
      "source": [
        "# Model Aggregation (Federated Averaging)\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8uvmfM34iKE"
      },
      "source": [
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the bs\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
        "    return local_count/global_count\n",
        "\n",
        "\n",
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final\n",
        "\n",
        "def noisy_weights(weight,fade):\n",
        "    '''function for add channel to weights'''\n",
        "    weight_final_n = []\n",
        "    sp = len(weight)\n",
        "    for i in range(sp):\n",
        "        noisy=fade * weight[i]\n",
        "        weight_final_n.append(noisy)\n",
        "    return weight_final_n\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list , noisee):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0) + noisee\n",
        "        avg_grad.append(layer_mean)\n",
        "\n",
        "    return avg_grad\n",
        "\n",
        "\n",
        "def test_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.SquaredHinge()\n",
        "    #cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    #logits = model.predict(X_test, batch_size=100)\n",
        "    y_pred = model.predict(X_test)\n",
        "    loss = cce(Y_test, y_pred)\n",
        "    acc = accuracy_score(tf.argmax(y_pred, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOUNcPjCqFyr"
      },
      "source": [
        "# Federated Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRWGW34YSsHg"
      },
      "source": [
        "import math\n",
        "from numpy import sqrt\n",
        "import random\n",
        "\n",
        "#generate parameter\n",
        "roh= 4        # s values of average transmit SNR ?¯ = P/? ^2 db (9 , 4 , -1) by default set as 4 dB.\n",
        "transmission_budget = 4000   # The maximum transmission budget N is set to be 4000\n",
        "theta_snr=10   # channel-aware ARQ with three SNR thresholds  = 10; 25 and 30 dB\n",
        "pc = 0.730     # importance ARQ are considered by the data-alignment probability: pc = 0.730; 0.800 and 0.999.\n",
        "noise_std = 1\n",
        "noise_mean = 0\n",
        "acc2=[]\n",
        "N=1\n",
        "\n",
        "\n",
        "#We learn the digits on train part\n",
        "start_time = dt.datetime.now()\n",
        "print('Start learning at {}'.format(str(start_time)))\n",
        "\n",
        "#initialize global model\n",
        "smlp_global = SimpleMLP()\n",
        "global_model = smlp_global.build(input_shape, 10)\n",
        "\n",
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "\n",
        "    #loop through each client and create new local model\n",
        "    for client in client_names:\n",
        "        smlp_local = SimpleMLP()\n",
        "        #local_model = smlp_local.build(784, 10)\n",
        "        local_model = smlp_local.build(input_shape, 10)\n",
        "        local_model.compile(loss=loss,\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=metrics)\n",
        "\n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
        "\n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "\n",
        "        #Transmit weights through a fading + AWGN channel\n",
        "        #noise1 = random.gauss(noise_mean, noise_std)  # genarate noise\n",
        "        noise1=0\n",
        "        fade = sqrt(random.gauss(0,1)**2+random.gauss(0,1)**2)/sqrt(2)   #abs rayleight channel   #Genrate a mutli-path fading channel\n",
        "        noisy_scaled_weights=noisy_weights(scaled_weights,fade)\n",
        "\n",
        "        '''\n",
        "        ## ARQ\n",
        "        snr_h=2 *roh*(fade**2)\n",
        "        while snr_h < theta_snr :\n",
        "              print(\"NAK of Frame Received\\n \")\n",
        "              #noise1 = random.gauss(noise_mean, noise_std)  # genarate noise\n",
        "              noise1=0\n",
        "              fade = sqrt(random.gauss(0,1)**2+random.gauss(0,1)**2)/sqrt(2)   #abs rayleight channel   #Genrate a mutli-path fading channel\n",
        "              noisy_scaled_weights=noisy_weights(scaled_weights,fade)\n",
        "              snr_h= 2 *roh*(fade**2)\n",
        "\n",
        "        '''\n",
        "\n",
        "        scaled_local_weight_list.append(noisy_scaled_weights)\n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "\n",
        "\n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list , noise1)\n",
        "\n",
        "    #update global model\n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, y_test, global_model, comm_round)\n",
        "        acc2.append(global_acc * 100)\n",
        "\n",
        "\n",
        "end_time = dt.datetime.now()\n",
        "print('Stop learning {}'.format(str(end_time)))\n",
        "elapsed_time= end_time - start_time\n",
        "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
        "\n",
        "\n",
        "plt.plot(range (0, len(acc2)),acc2, 'r*-')\n",
        "plt.title('ARQ')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89f5Qi8GrQyw"
      },
      "source": [
        "# standard SGD model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEyybwUZ5iPL"
      },
      "source": [
        "SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(batch_size)\n",
        "smlp_SGD = SimpleMLP()\n",
        "SGD_model = smlp_SGD.build(input_shape, 10)\n",
        "\n",
        "SGD_model.compile(loss=loss,\n",
        "              optimizer=optimizer,\n",
        "              metrics=metrics)\n",
        "\n",
        "# fit the SGD training data to model\n",
        "_ = SGD_model.fit(SGD_dataset, epochs=comms_round, verbose=1 , validation_data=(X_test, y_test))\n",
        "\n",
        "#test the SGD global model and print out metrics\n",
        "#for(X_test, y_test) in test_batched:\n",
        "#        SGD_acc, SGD_loss = test_model(X_test, y_test, SGD_model, 1)\n",
        "\n",
        "score=SGD_model.evaluate(X_test , y_test , batch_size=batch_size , verbose= 1)\n",
        "print('Test_acc: {:.3%} | Test_loss: {}'.format( score[1], score[0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}